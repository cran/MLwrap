% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/plotting_utils.R
\name{plot_confusion_matrix}
\alias{plot_confusion_matrix}
\title{Plotting Confusion Matrix}
\usage{
plot_confusion_matrix(analysis_object)
}
\arguments{
\item{analysis_object}{Fitted analysis_object with 'fine_tuning()'.}
}
\value{
analysis_object
}
\description{
The \strong{plot_confusion_matrix()} function generates confusion matrices from
classification predictions displaying the contingency table of true class
labels versus predicted class labels. Visualizes true positives, true
negatives, false positives, and false negatives for both training and test
sets, enabling computation of derived performance metrics (sensitivity,
specificity, precision, F1-score) and identification of specific class pair
misclassification patterns.
}
\examples{
# Note: For obtaining confusion matrix plot the user needs to
# complete till fine_tuning( ) function of the MLwrap pipeline and
# only with categorical outcome.
# See the full pipeline example under plot_calibration_curve()
# Final call signature:
# plot_confusion_matrix(wrap_object)
}
\seealso{
\code{\link{plot_calibration_curve}}
}
